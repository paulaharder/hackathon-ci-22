{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f505cb1-daba-41c1-aa76-1fcf09b19155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1bcc6c-18ae-4cca-9466-d58a63231788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_predictors_predictands(start_date, end_date, lead_time, dataset, num_input_time_steps):\n",
    "    '''\n",
    "    Args\n",
    "    ----\n",
    "\n",
    "    start_date (str): The start date for extraction. Important, put the trailing 0 at the beginning of year for dates before 1000 (e.g., '0400')\n",
    "    end_date (str): The end date for extraction\n",
    "    lead_time (int): The number of months between the predictor/predictand\n",
    "    dataset (str): Either 'CESM' or 'ECMWF'\n",
    "    num_input_time_steps (int): The number of time steps to use for each predictor samples\n",
    "\n",
    "    '''    \n",
    "\n",
    "    file_name = {'CESM': 'CESM_EA_SPI.nc', 'ECMWF': 'ECMWF_EA_SPI.nc'}[dataset]\n",
    "\n",
    "    ds = xr.open_dataset(file_name)\n",
    "    spi = ds['spi'].sel(time=slice(start_date,end_date))\n",
    "\n",
    "    num_samples=spi.shape[0]\n",
    "\n",
    "    #Stack and remove nans\n",
    "    spi = np.stack([spi.values[n-num_input_time_steps:n] for n in range(num_input_time_steps, num_samples+1)])\n",
    "    num_samples = spi.shape[0]\n",
    "    spi[np.isnan(spi)] = 0\n",
    "\n",
    "    #make sure we have floats in there\n",
    "    X = spi.astype(np.float32)\n",
    "\n",
    "    # select Y\n",
    "    if dataset == 'ECMWF':\n",
    "        start_date_plus_lead = pd.to_datetime(start_date) + pd.DateOffset(months=lead_time+num_input_time_steps-1)\n",
    "        end_date_plus_lead = pd.to_datetime(end_date) + pd.DateOffset(months=lead_time)\n",
    "\n",
    "    elif dataset == 'CESM':\n",
    "        t_start=datetime.datetime(int(start_date.split('-')[0]),int(start_date.split('-')[1]),int(start_date.split('-')[2]))\n",
    "        t_end=datetime.datetime(int(end_date.split('-')[0]),int(end_date.split('-')[1]),int(end_date.split('-')[2]))\n",
    "        start_date_plus_lead = t_start + relativedelta(months=lead_time+num_input_time_steps-1)\n",
    "        end_date_plus_lead = t_end + relativedelta(months=lead_time)\n",
    "        #target_start_date_with_2_month = start_date_plus_lead - relativedelta(months=2)\n",
    "        if len(str(start_date_plus_lead.year))<4:\n",
    "            start_date_plus_lead = '0'+start_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        elif len(str(start_date_plus_lead.year))==4:\n",
    "            start_date_plus_lead = start_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        if len(str(end_date_plus_lead.year))<4:\n",
    "            end_date_plus_lead = '0'+end_date_plus_lead.strftime('%Y-%m-%d')\n",
    "        elif len(str(end_date_plus_lead.year))==4:\n",
    "            end_date_plus_lead = end_date_plus_lead.strftime('%Y-%m-%d')\n",
    "\n",
    "    subsetted_ds = ds['spi'].sel(time=slice(start_date_plus_lead,\n",
    "                                                 end_date_plus_lead))\n",
    "    f = subsetted_ds. values.astype(np.float32)\n",
    "    f[np.isnan(f)] = 0\n",
    "    ds.close()\n",
    "\n",
    "    return X,f\n",
    "\n",
    "class SPIDataset(Dataset):\n",
    "    def __init__(self, predictors, predictands):\n",
    "        self.predictors = predictors\n",
    "        self.predictands = np.expand_dims(predictands, axis=1)\n",
    "        assert self.predictors.shape[0] == self.predictands.shape[0], \\\n",
    "                   \"The number of predictors must equal the number of predictands!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.predictors.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.predictors[idx], self.predictands[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060f2ceb-ea19-4169-a940-c0b3b22aa559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_input_time_steps=1, print_feature_dimension=False):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "        -------\n",
    "            num_input_time_steps        (int) : the number of input time\n",
    "                                                steps in the predictor\n",
    "            print_feature_dimension    (bool) : whether or not to print\n",
    "                                                out the dimension of the features\n",
    "                                                extracted from the conv layers\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_input_time_steps, out_channels=6,  kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16,  kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=42,  kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=42, out_channels=1,  kernel_size=3, padding=1)\n",
    "        self.print_layer = Print()\n",
    "        self.print_feature_dimension = print_feature_dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        if self.print_feature_dimension:\n",
    "            x = self.print_layer(x)\n",
    "        x = self.conv4(x)\n",
    "        return x\n",
    "\n",
    "class Print(nn.Module):\n",
    "    \"\"\"\n",
    "    This class prints out the size of the features\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fd05d9-c92c-438a-be7d-ff3537c175fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(net, criterion, optimizer, trainloader, testloader, experiment_name, num_epochs=40):\n",
    "    \"\"\"\n",
    "    inputs\n",
    "    ------\n",
    "\n",
    "      net               (nn.Module)   : the neural network architecture\n",
    "      criterion         (nn)          : the loss function (i.e. root mean squared error)\n",
    "      optimizer         (torch.optim) : the optimizer to use update the neural network \n",
    "                                        architecture to minimize the loss function\n",
    "      trainloader       (torch.utils.data.DataLoader): dataloader that loads the\n",
    "                                        predictors and predictands\n",
    "                                        for the train dataset\n",
    "      testloader        (torch.utils.data. DataLoader): dataloader that loads the\n",
    "                                        predictors and predictands\n",
    "                                        for the test dataset\n",
    "      experiment_name   Name of the experiment (for visualization purposes)\n",
    "      num_epochs        Number of epochs (default=40)\n",
    "\n",
    "\n",
    "    outputs\n",
    "    -------\n",
    "      predictions (np.array), and saves the trained neural network as a .pt file\n",
    "    \"\"\"\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    net = net.to(device)\n",
    "    best_loss = np.infty\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for mode, data_loader in [('train', trainloader), ('test', testloader)]:\n",
    "            #Set the model to train mode to allow its weights to be updated\n",
    "            #while training\n",
    "            if mode == 'train':\n",
    "                net.train()\n",
    "\n",
    "            #Set the model to eval model to prevent its weights from being updated\n",
    "            #while testing\n",
    "            elif mode == 'test':\n",
    "                net.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(data_loader):\n",
    "                # get a mini-batch of predictors and predictands\n",
    "                batch_predictors, batch_predictands = data\n",
    "                batch_predictands = batch_predictands.to(device)\n",
    "                batch_predictors = batch_predictors.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #calculate the predictions of the current neural network\n",
    "                predictions = net(batch_predictors)\n",
    "\n",
    "                #quantify the quality of the predictions using a\n",
    "                #loss function (aka criterion) that is differentiable\n",
    "                loss = criterion(predictions, batch_predictands)\n",
    "\n",
    "                if mode == 'train':\n",
    "                    #the 'backward pass: calculates the gradients of each weight\n",
    "                    #of the neural network with respect to the loss\n",
    "                    loss.backward()\n",
    "\n",
    "                    #the optimizer updates the weights of the neural network\n",
    "                    #based on the gradients calculated above and the choice\n",
    "                    #of optimization algorithm\n",
    "                    optimizer.step()\n",
    "\n",
    "                #Save the model weights that have the best performance!\n",
    "                running_loss += loss.item()\n",
    "                if running_loss < best_loss and mode == 'test':\n",
    "                    best_loss = running_loss\n",
    "                    torch.save(net.state_dict(), '{}.pt'.format(experiment_name))\n",
    "            print('{} Set: Epoch {:02d}. loss: {:3f}'.format(mode, epoch+1, running_loss/len(data_loader)))\n",
    "            if mode == 'train':\n",
    "                train_losses.append(running_loss/len(data_loader))\n",
    "            else:\n",
    "                test_losses.append(running_loss/len(data_loader))\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bb61fd-f021-4243-ad67-f2399414a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(testloader,experiment_name,num_input_time_steps):\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    net = CNN(num_input_time_steps,False)\n",
    "    net.load_state_dict(torch.load('{}.pt'.format(experiment_name)))\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "\n",
    "    #the remainder of this notebook calculates the predictions of the best\n",
    "    #saved model\n",
    "    for i, data in enumerate(testloader):\n",
    "        batch_predictors, batch_predictands = data\n",
    "        batch_predictands = batch_predictands.to(device)\n",
    "        batch_predictors = batch_predictors.to(device)\n",
    "\n",
    "        batch_predictions = net(batch_predictors).squeeze()\n",
    "        batch_predictions = batch_predictions.detach().cpu().numpy()\n",
    "        try:   \n",
    "            predictions = np.vstack((predictions, batch_predictions))\n",
    "        except NameError:\n",
    "            predictions = batch_predictions\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da84346-0c62-4d49-8c12-30f57c4da482",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parameters\n",
    "num_input_time_steps = 3 \n",
    "lead_time = 3\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "climate_model = 'CESM'\n",
    "train_start_date = '0400-01-01'\n",
    "train_end_date = '1800-12-31'\n",
    "\n",
    "test_start_date = '1801-01-01'\n",
    "test_end_date = '1978-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd66c93-9571-4747-a5fb-a661a50e07b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Set: Epoch 01. loss: 0.984806\n",
      "test Set: Epoch 01. loss: 1.033687\n",
      "train Set: Epoch 02. loss: 0.962742\n",
      "test Set: Epoch 02. loss: 1.003473\n",
      "train Set: Epoch 03. loss: 0.927999\n",
      "test Set: Epoch 03. loss: 0.956436\n",
      "train Set: Epoch 04. loss: 0.880773\n",
      "test Set: Epoch 04. loss: 0.901926\n",
      "train Set: Epoch 05. loss: 0.834239\n",
      "test Set: Epoch 05. loss: 0.857340\n",
      "train Set: Epoch 06. loss: 0.802458\n",
      "test Set: Epoch 06. loss: 0.831040\n",
      "train Set: Epoch 07. loss: 0.784014\n",
      "test Set: Epoch 07. loss: 0.815098\n",
      "train Set: Epoch 08. loss: 0.771811\n",
      "test Set: Epoch 08. loss: 0.804307\n",
      "train Set: Epoch 09. loss: 0.763269\n",
      "test Set: Epoch 09. loss: 0.796932\n",
      "train Set: Epoch 10. loss: 0.757236\n",
      "test Set: Epoch 10. loss: 0.791715\n",
      "train Set: Epoch 11. loss: 0.752739\n",
      "test Set: Epoch 11. loss: 0.787744\n",
      "train Set: Epoch 12. loss: 0.749135\n",
      "test Set: Epoch 12. loss: 0.784487\n",
      "train Set: Epoch 13. loss: 0.746067\n",
      "test Set: Epoch 13. loss: 0.781628\n",
      "train Set: Epoch 14. loss: 0.743327\n",
      "test Set: Epoch 14. loss: 0.779069\n",
      "train Set: Epoch 15. loss: 0.740880\n",
      "test Set: Epoch 15. loss: 0.776777\n",
      "train Set: Epoch 16. loss: 0.738676\n",
      "test Set: Epoch 16. loss: 0.774702\n",
      "train Set: Epoch 17. loss: 0.736675\n",
      "test Set: Epoch 17. loss: 0.772811\n",
      "train Set: Epoch 18. loss: 0.734850\n",
      "test Set: Epoch 18. loss: 0.771089\n",
      "train Set: Epoch 19. loss: 0.733175\n",
      "test Set: Epoch 19. loss: 0.769499\n",
      "train Set: Epoch 20. loss: 0.731621\n",
      "test Set: Epoch 20. loss: 0.768014\n",
      "train Set: Epoch 21. loss: 0.730170\n",
      "test Set: Epoch 21. loss: 0.766615\n",
      "train Set: Epoch 22. loss: 0.728804\n",
      "test Set: Epoch 22. loss: 0.765294\n",
      "train Set: Epoch 23. loss: 0.727513\n",
      "test Set: Epoch 23. loss: 0.764036\n",
      "train Set: Epoch 24. loss: 0.726280\n",
      "test Set: Epoch 24. loss: 0.762816\n",
      "train Set: Epoch 25. loss: 0.725078\n",
      "test Set: Epoch 25. loss: 0.761616\n",
      "train Set: Epoch 26. loss: 0.723912\n",
      "test Set: Epoch 26. loss: 0.760467\n",
      "train Set: Epoch 27. loss: 0.722805\n",
      "test Set: Epoch 27. loss: 0.759369\n",
      "train Set: Epoch 28. loss: 0.721756\n",
      "test Set: Epoch 28. loss: 0.758326\n",
      "train Set: Epoch 29. loss: 0.720759\n",
      "test Set: Epoch 29. loss: 0.757334\n",
      "train Set: Epoch 30. loss: 0.719809\n",
      "test Set: Epoch 30. loss: 0.756389\n",
      "train Set: Epoch 31. loss: 0.718899\n",
      "test Set: Epoch 31. loss: 0.755483\n",
      "train Set: Epoch 32. loss: 0.718024\n",
      "test Set: Epoch 32. loss: 0.754612\n",
      "train Set: Epoch 33. loss: 0.717180\n",
      "test Set: Epoch 33. loss: 0.753773\n",
      "train Set: Epoch 34. loss: 0.716367\n",
      "test Set: Epoch 34. loss: 0.752963\n",
      "train Set: Epoch 35. loss: 0.715583\n",
      "test Set: Epoch 35. loss: 0.752182\n",
      "train Set: Epoch 36. loss: 0.714826\n",
      "test Set: Epoch 36. loss: 0.751429\n",
      "train Set: Epoch 37. loss: 0.714095\n",
      "test Set: Epoch 37. loss: 0.750703\n",
      "train Set: Epoch 38. loss: 0.713390\n",
      "test Set: Epoch 38. loss: 0.750002\n",
      "train Set: Epoch 39. loss: 0.712709\n",
      "test Set: Epoch 39. loss: 0.749327\n",
      "train Set: Epoch 40. loss: 0.712052\n",
      "test Set: Epoch 40. loss: 0.748673\n",
      "train Set: Epoch 41. loss: 0.711417\n",
      "test Set: Epoch 41. loss: 0.748043\n",
      "train Set: Epoch 42. loss: 0.710802\n",
      "test Set: Epoch 42. loss: 0.747433\n",
      "train Set: Epoch 43. loss: 0.710207\n",
      "test Set: Epoch 43. loss: 0.746843\n",
      "train Set: Epoch 44. loss: 0.709631\n",
      "test Set: Epoch 44. loss: 0.746270\n",
      "train Set: Epoch 45. loss: 0.709073\n",
      "test Set: Epoch 45. loss: 0.745715\n",
      "train Set: Epoch 46. loss: 0.708531\n",
      "test Set: Epoch 46. loss: 0.745176\n",
      "train Set: Epoch 47. loss: 0.708005\n",
      "test Set: Epoch 47. loss: 0.744651\n",
      "train Set: Epoch 48. loss: 0.707495\n",
      "test Set: Epoch 48. loss: 0.744140\n",
      "train Set: Epoch 49. loss: 0.706998\n",
      "test Set: Epoch 49. loss: 0.743644\n",
      "train Set: Epoch 50. loss: 0.706514\n",
      "test Set: Epoch 50. loss: 0.743160\n",
      "train Set: Epoch 51. loss: 0.706043\n",
      "test Set: Epoch 51. loss: 0.742688\n",
      "train Set: Epoch 52. loss: 0.705584\n",
      "test Set: Epoch 52. loss: 0.742229\n",
      "train Set: Epoch 53. loss: 0.705137\n",
      "test Set: Epoch 53. loss: 0.741780\n",
      "train Set: Epoch 54. loss: 0.704699\n",
      "test Set: Epoch 54. loss: 0.741344\n",
      "train Set: Epoch 55. loss: 0.704273\n",
      "test Set: Epoch 55. loss: 0.740918\n",
      "train Set: Epoch 56. loss: 0.703855\n",
      "test Set: Epoch 56. loss: 0.740502\n",
      "train Set: Epoch 57. loss: 0.703448\n",
      "test Set: Epoch 57. loss: 0.740094\n",
      "train Set: Epoch 58. loss: 0.703050\n",
      "test Set: Epoch 58. loss: 0.739697\n",
      "train Set: Epoch 59. loss: 0.702660\n",
      "test Set: Epoch 59. loss: 0.739308\n",
      "train Set: Epoch 60. loss: 0.702279\n",
      "test Set: Epoch 60. loss: 0.738927\n",
      "train Set: Epoch 61. loss: 0.701906\n",
      "test Set: Epoch 61. loss: 0.738555\n",
      "train Set: Epoch 62. loss: 0.701541\n",
      "test Set: Epoch 62. loss: 0.738191\n",
      "train Set: Epoch 63. loss: 0.701183\n",
      "test Set: Epoch 63. loss: 0.737833\n",
      "train Set: Epoch 64. loss: 0.700832\n",
      "test Set: Epoch 64. loss: 0.737484\n",
      "train Set: Epoch 65. loss: 0.700489\n",
      "test Set: Epoch 65. loss: 0.737142\n",
      "train Set: Epoch 66. loss: 0.700153\n",
      "test Set: Epoch 66. loss: 0.736808\n",
      "train Set: Epoch 67. loss: 0.699823\n",
      "test Set: Epoch 67. loss: 0.736480\n",
      "train Set: Epoch 68. loss: 0.699500\n",
      "test Set: Epoch 68. loss: 0.736158\n",
      "train Set: Epoch 69. loss: 0.699184\n",
      "test Set: Epoch 69. loss: 0.735843\n",
      "train Set: Epoch 70. loss: 0.698873\n",
      "test Set: Epoch 70. loss: 0.735534\n",
      "train Set: Epoch 71. loss: 0.698569\n",
      "test Set: Epoch 71. loss: 0.735232\n",
      "train Set: Epoch 72. loss: 0.698271\n",
      "test Set: Epoch 72. loss: 0.734936\n",
      "train Set: Epoch 73. loss: 0.697978\n",
      "test Set: Epoch 73. loss: 0.734645\n",
      "train Set: Epoch 74. loss: 0.697690\n",
      "test Set: Epoch 74. loss: 0.734360\n",
      "train Set: Epoch 75. loss: 0.697408\n",
      "test Set: Epoch 75. loss: 0.734080\n",
      "train Set: Epoch 76. loss: 0.697132\n",
      "test Set: Epoch 76. loss: 0.733805\n",
      "train Set: Epoch 77. loss: 0.696860\n",
      "test Set: Epoch 77. loss: 0.733535\n",
      "train Set: Epoch 78. loss: 0.696594\n",
      "test Set: Epoch 78. loss: 0.733271\n",
      "train Set: Epoch 79. loss: 0.696333\n",
      "test Set: Epoch 79. loss: 0.733012\n",
      "train Set: Epoch 80. loss: 0.696077\n",
      "test Set: Epoch 80. loss: 0.732758\n",
      "train Set: Epoch 81. loss: 0.695826\n",
      "test Set: Epoch 81. loss: 0.732508\n",
      "train Set: Epoch 82. loss: 0.695578\n",
      "test Set: Epoch 82. loss: 0.732263\n",
      "train Set: Epoch 83. loss: 0.695336\n",
      "test Set: Epoch 83. loss: 0.732022\n",
      "train Set: Epoch 84. loss: 0.695097\n",
      "test Set: Epoch 84. loss: 0.731786\n",
      "train Set: Epoch 85. loss: 0.694863\n",
      "test Set: Epoch 85. loss: 0.731553\n",
      "train Set: Epoch 86. loss: 0.694632\n",
      "test Set: Epoch 86. loss: 0.731325\n",
      "train Set: Epoch 87. loss: 0.694406\n",
      "test Set: Epoch 87. loss: 0.731102\n",
      "train Set: Epoch 88. loss: 0.694183\n",
      "test Set: Epoch 88. loss: 0.730882\n",
      "train Set: Epoch 89. loss: 0.693964\n",
      "test Set: Epoch 89. loss: 0.730666\n",
      "train Set: Epoch 90. loss: 0.693749\n",
      "test Set: Epoch 90. loss: 0.730454\n",
      "train Set: Epoch 91. loss: 0.693537\n",
      "test Set: Epoch 91. loss: 0.730245\n",
      "train Set: Epoch 92. loss: 0.693329\n",
      "test Set: Epoch 92. loss: 0.730040\n",
      "train Set: Epoch 93. loss: 0.693125\n",
      "test Set: Epoch 93. loss: 0.729839\n",
      "train Set: Epoch 94. loss: 0.692924\n",
      "test Set: Epoch 94. loss: 0.729642\n",
      "train Set: Epoch 95. loss: 0.692726\n",
      "test Set: Epoch 95. loss: 0.729448\n",
      "train Set: Epoch 96. loss: 0.692531\n",
      "test Set: Epoch 96. loss: 0.729257\n",
      "train Set: Epoch 97. loss: 0.692340\n",
      "test Set: Epoch 97. loss: 0.729069\n",
      "train Set: Epoch 98. loss: 0.692152\n",
      "test Set: Epoch 98. loss: 0.728884\n",
      "train Set: Epoch 99. loss: 0.691968\n",
      "test Set: Epoch 99. loss: 0.728702\n",
      "train Set: Epoch 100. loss: 0.691785\n",
      "test Set: Epoch 100. loss: 0.728522\n"
     ]
    }
   ],
   "source": [
    "train_predictors, train_predictands = assemble_predictors_predictands(train_start_date, train_end_date, lead_time, climate_model, num_input_time_steps)\n",
    "test_predictors, test_predictands = assemble_predictors_predictands(test_start_date, test_end_date, lead_time, climate_model,num_input_time_steps)\n",
    "\n",
    "#Convert the numpy ararys into ENSODataset, which is a subset of the \n",
    "#torch.utils.data.Dataset class.  This class is compatible with\n",
    "#the torch dataloader, which allows for data loading for a CNN\n",
    "train_dataset = SPIDataset(train_predictors, train_predictands)\n",
    "test_dataset = SPIDataset(test_predictors, test_predictands)\n",
    "\n",
    "#Create a torch.utils.data.DataLoader from the ENSODatasets() created earlier!\n",
    "#the similarity between the name DataLoader and Dataset in the pytorch API is unfortunate...\n",
    "trainloader = DataLoader(train_dataset, batch_size=100)\n",
    "testloader = DataLoader(test_dataset, batch_size=100)\n",
    "net = CNN(num_input_time_steps=num_input_time_steps)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00001)\n",
    "\n",
    "experiment_name = \"threelayerCNN_{}_{}_{}\".format(train_start_date, train_end_date,lead_time)\n",
    "train_losses, test_losses = train_network(net, nn.MSELoss(), optimizer, trainloader, testloader, experiment_name, num_epochs)\n",
    "predictions = test_network(testloader,experiment_name,num_input_time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4866491-3384-487a-aee7-169df5011e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Look at learning curves\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Performance of {} Neural Network During Training'.format(experiment_name))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dc66b-1cd0-42c1-b719-4f929591d5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
